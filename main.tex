% Template for a Computer Science Tripos Part II project dissertation
\documentclass[12pt,a4paper,twoside,openright]{report}
\usepackage[pdfborder={0 0 0}]{hyperref}    % turns references into hyperlinks
\usepackage[left=25mm, right=25mm, bottom=25mm, top=20mm]{geometry}  % adjusts page layout
\usepackage{graphicx}  % allows inclusion of PDF, PNG and JPG images
\usepackage{subcaption}
\usepackage{verbatim}
\usepackage{amsfonts}
\usepackage{xcolor}
\usepackage{placeins}
\usepackage{amsthm}
\usepackage{amsmath}
\usepackage{tabu}
\usepackage{docmute}   % only needed to allow inclusion of proposal.tex
\usepackage[utf8]{inputenc}
\usepackage{mathtools}
\usepackage{changepage}
\usepackage{url}
\usepackage{blindtext}
\usepackage{tabularx,booktabs}
\usepackage{dirtree}
\usepackage{cite}
\usepackage{float} % Prevent Latex from repositioning tables
\usepackage{graphicx}

%--- Remove hbox warning
\hfuzz=5000.002pt 
%----------------------------------------------------------------------------------------

% Formatting Commands
\newcommand{\keyword}[1]{\textbf{#1}}
\newcommand{\tabhead}[1]{\textbf{#1}}
\newcommand{\code}[1]{\texttt{#1}}
\newcommand{\file}[1]{\texttt{\bfseries#1}}
\newcommand{\option}[1]{\texttt{\itshape#1}}

%----------------------------------------------------------------------------------------
%% *****************************************************************
\newlength{\upBranch} % shift up the text  lines <<<<
\setlength{\upBranch}{0.7ex} % 

\newlength{\tolineSpace} % blank space bellow text  lines  <<<
\setlength{\tolineSpace}{1mm}% 

\usepackage{xpatch} % needed <<<<<<<<
\makeatletter

\xpatchcmd{\dirtree} % root
{\vbox{\@nameuse{DT@body@1}}}
{\raisebox{-\tolineSpace}{\vbox{\@nameuse{DT@body@1}}}}
{}{}    

\xpatchcmd{\dirtree} % below space
{\advance\dimen\z@ by-\@nameuse{DT@lastlevel@\the\DT@countiv}\relax}
{\advance\dimen\z@ by-\tolineSpace \advance\dimen\z@ by-\@nameuse{DT@lastlevel@\the\DT@countiv}\relax}
{}{}
    
\xpatchcmd{\dirtree}% shift up the text  lines
{\kern\DT@sep\box\z@\endgraf}
{\kern\DT@sep\raisebox{-\upBranch}{\box\z@}\endgraf}
{}{}    

\makeatother
%% *****************************************************************


%-----
% Language setting
\usepackage[english]{babel}
%\raggedbottom                           % try to avoid widows and orphans
\sloppy
\clubpenalty1000%
\widowpenalty1000%

\renewcommand{\baselinestretch}{1.1}    % adjust line spacing to make
                                        % more readable


\theoremstyle{definition}
\newtheorem{definition}{Definition}[section]

\graphicspath{{figs/}}

\begin{document}

\include{metadata}

\bibliographystyle{acm}


\setlength{\parskip}{10pt}
\setlength{\parindent}{0pt}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Title
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\thispagestyle{empty}

\rightline{\LARGE \textbf{\mfullname}}

\vspace*{60mm}
\begin{center}
\Huge
\textbf{\mtitle} \\[5mm]
\mexamination \\[5mm]
\mcollege \\[5mm]
\mdate  % today's date
\end{center}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Proforma, table of contents and list of figures
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\pagestyle{plain}

\newpage
\newpage
\section*{Declaration of originality}

I, \mfullname{} of \mcollege, being a candidate for Part II of the Computer Science Tripos, hereby declare that this dissertation and the work described in it are my own work, unaided except as may be specified below, and that the dissertation does not contain material that has already been used to any substantial extent for a comparable purpose. \mconsent

\bigskip
\leftline{Signed \msignature}
\bigskip
\leftline{Date \today}

\chapter*{Proforma}

% \hbadness=0

{\large
  \begin{tabular}{ll}
Candidate Number:   & \bf \mcandidate                   \\
Project Title:      & \bf \mtitle                       \\
Examination:        & \bf \mexamination, \mdate         \\
Word Count:         & \bf \mwordcount\footnotemark[1]   \\
Code Line Count:    & \bf \mlinecount\footnotemark[2]   \\
Project Originator: & \bf \moriginator                  \\
Supervisor:         & \bf \msupervisor                  \\ 
\end{tabular}
}

\footnotetext[1]{This word count was computed
by \texttt{texcount main.tex}
}
\footnotetext[2]{This code line count was computed
by using \texttt{cloc}
}
\stepcounter{footnote}

\section*{Original Aims of the Project}
The original aim was to implement a parsing algorithm for symbolic music, using the derivation to infer the underlying harmonic structure, then explore data driven approaches for heuristic design.


\section*{Work Completed}



\section*{Special Difficulties}
There were no special difficulties encountered in this project

\newpage
{
\renewcommand{\baselinestretch}{0.75}\normalsize
\tableofcontents
\renewcommand{\baselinestretch}{1.0}\normalsize
}
\listoffigures

\newpage
\section*{Acknowledgements}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% now for the chapters

\pagestyle{headings}

\chapter{Introduction}
\textit{This dissertation explores efficient search strategies for parsing symbolic music data using a musical grammar for Automatic Chord Estimation (ACE). We first present a naive implementation of a parsing algorithm based on a recent grammatical model, then address problems of intractability through classical heuristic search methods. We will see that that my novel heuristic search algorithm achieves commendable results, providing a strong foundation for a more sophisticated automated analysis system. }

\section{Motivation}

Most of western tonal music can be described using a sequence of chords, representing a higher level harmonic structure of a piece. Automatic Chord Estimation (ACE) is the task of inferring the sequence of chords for a given piece from symbolic (such as a score) or audio data. There is a small, finite set of chord types, but each chord can be realised on the musical surface in a practically infinite number of ways. Given a score (a symbolic representation of a piece of music), we wish to infer the sequence of underlying chord types. 
\par
Automatic Chord Estimation has both theoretical and practical applications. Novel ways to understand harmonic structure are sought after by music theorists, aiding the analysis and composition of pieces. Analysis of music often starts with the manual labeling each chord, which is a time consuming and cogntively demanding expert task. Sequences of chords provide compact representations for use in analysis, music identification and music similarity finding. More broadly speaking, any system that involves the understanding of written music will benefit from chord estimation. 
\par
The paper \textit{Modeling and Inferring Protovoice Structure in Free Polyphony} describes a generative model that encodes the recursive and hierarchical dependencies between notes, giving rise to a grammar-like hierarchical system \cite{finkensiepModelingInferringProtovoice2021}. This protovoice model can be used to reduce a piece into a hierarchical structure which encodes an understanding of the tonal/harmonic relations.
\par
Insert descriptive diagram???
\par
Finkensiep suggests in his thesis that the protovoice model may be an effective way to infer higher level latent entities such as harmonies. Thus, in this project I will answer the question: is this model an effective way to annotate harmonies? By ‘effective’ we are referring to two things:
\begin{itemize}
  \item Accuracy: can the model successfully emulate how experts annotate harmonic progressions in musical passages? 
  \item Practicality: can the model be used to do this within a reasonable time frame?
\end{itemize}

While the original model could in theory be used to generate harmonic annotations, an exhaustive search strategy would be prohibitively time-consuming in practice for any but the shortest musical extracts; one half measure can have over 100,000 valid derivations \cite{finkensiepStructureFreePolyphony2023}. My approach will be to explore the use of heuristic search algorithms to solve this problem.

\section{Related Work}

% The problem of automated chord estimation has been subject to attention since the 80s, with handcrafted grammar/rule-based being. 
Automatic chord estimation systems first emerged in in the 60's, making use of handcrafted grammar/rule-based systems \cite{maxwellExpertSystemHarmonizing1992} \cite{winogradLinguisticsComputerAnalysis1968}, followed by the development of optimisation algorithms in the early 2000s \cite{pardoAlgorithmsChordalAnalysis2002}. In more recent years, supervised learning approaches have have risen in popularity, exploiting large datasets and improved compute power \cite{niEndtoendMachineLearning2011} \cite{mcleodModularSystemHarmonic2021} \cite{masadaChordRecognitionSymbolic2018}. 
\par 
The protovoice model is the first to provide a unified theory that relates three aspects of tonal music analysis that are typically considered independently: voice-leading, how notes relate to each other \textit{sequentially}; harmony, how notes relate to each other through \textit{simulataneity}; and note function, how notes relate to each other through recursive \textit{functional dependencies}. Previous models have been developed alongside parsing algorithms to perform automatic chord estimation that consider these dimensions of musical structure separately \cite{maxwellExpertSystemHarmonizing1992} \cite{winogradLinguisticsComputerAnalysis1968}, but in this project we use the relationship between these dimensions of music as the basis of heuristic design.
\par
% Distinction to be drawn between approaches that take segmented or non-segmented pieces. Some models make use of a joint segmentation and labelling approach \cite{masadaChordRecognitionSymbolic2018}. 

\section{Achievements}

This was an ambitious project, and I met all of my success criteria and completed the extension tasks. I show that the protovoice model can be used to effectively annotate pieces with chord labels, and these results provide a promising foundation for the model being developed further as a sophisticated tool for the automated analysis of western total music.

% Blow my trumpet here. Overview of what I achieved, problems I solved etc. Say that this is forming a basis of an ISMIR 2023 submission.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Preparation
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{Preparation}
\textit{In this chapter, I present the work which was undertaken before the code was written. After a brief description of my starting point, I provide an exposition of the Protovoice Model which forms the foundation of this project. Subsequently, I discuss probabilistic programming and Bayesian inference, including a probabilistic model of harmony. Finally, I describe the software engineering techniques and principles used throughout the project. }

\section{Background Material}

\subsection{Voices}

The Protovoice model is a formal model concerned with the analysis of Western Classical music, although it could be adapted to different musical styles \cite{finkensiepStructureFreePolyphony2023}. 
% For the purposes of this dissertation I will make music theoretical assumptions, but their justification is left to the appendix.
\par
The input we are concerned with is called a score, a symbolic abstraction of a piece of music based on a 2-dimensional axis.

The marks on on score represents notes, with the pitch of the note corresponding to its position on the vertical axis\footnote{This is a simplification as there are other factors that determine the pitch, such as the key signature, accidentals and intonation.}, and the notes' position in time represented by the horizontal axis.
\begin{figure}
  \centering
  \includegraphics[width=0.85\textwidth]{scores/pitchTime.png}
  \captionsetup{width=.9\linewidth}
  \caption{An example of music notation. The five lines going across the page is the \textit{stave}. The three marks denote an ascending stepwise sequence.}
  \label{fig:pitchTime}
\end{figure}

The notion of a \textit{voice} is crucial for the understanding of the protovoice model. A voice typically refers to a single melodic line (sequence of notes) that is part of a musical composition. The term is derived from its use in choral music, such as J.S Bach's four-voice chorales, which consist of 4 sung melodic lines. The term voice is used is used more generally however, the melodic lines do not need to be sung or voice-like in character and can be performed by any melodic instrument. 
\FloatBarrier
\par
Polyphony refers to a piece of music that can contains more than one voice. Typically polyphonic music will have a set number of voices throughout the piece, but free polyphony refers to music where the number of voices is arbitrary and can change throughout the piece.
\par
\textit{Little diagram of a piece of music, with voices explicitly marked.}
\par

Three musical concepts that the protovoice model makes use of:

\subsubsection{Voice-leading} % (fold)
\label{sub:Voice-leading}
What are voices? Implicit vs Explicit voices. Define Stepwise

\begin{figure}
  \centering
  \includegraphics[width=0.45\textwidth]{scores/cadencevoices}
  \captionsetup{width=.9\linewidth}
  \caption{A short cadential phrases with the upper voice coloured blue. The final note shows the two voices meeting.}
  \label{fig:cadenceFunctions}
\end{figure}

% subsection Voice-leading (end)
\subsubsection{Harmony} % (fold)
\label{sub:Harmony}
notes that perceived as sounded simulatiously cause an emergent cognitive phenomonon of harmony, wherein the way the collection of notes sounds together depends on the pitch relationship between notes.

\begin{figure}
  \centering
  \includegraphics[width=0.45\textwidth]{scores/cadenceharmony}
  \captionsetup{width=.9\linewidth}
  \caption{Chord labels for the short cadential phrase, note that the second chord label, G, spans two groups of notes.}
  \label{fig:cadenceFunctions}
\end{figure}

% subsection Harmony (end)
\subsubsection{Functional Dependencies} % (fold)
\label{sub:Functional Dependencies}
Dependency relations refer to the purpose or function of a note relative to another note. 
Repetition/ ornamentation.

\begin{figure}
  \centering
  \includegraphics[width=0.45\textwidth]{scores/cadencefunctions}
  \captionsetup{width=.9\linewidth}
  \caption{Functional dependencies between notes. We show neighbour note relations in orange and repetitions in red.}
  \label{fig:cadenceFunctions}
\end{figure}

\FloatBarrier


% subsection Functional Dependencies (end)

\subsection{The Protovoice Model}
\par
The protovoice model is a generative model which represents a piece of music as a graph where each note is a node, and notes are connected by stepwise protovoice edges. It generates a piece of music through sequential operations on notes, inserting new notes with edges connected to existing notes.


\par 
\subsubsection{Inner Structure} % (fold)
\label{sub:Inner Structure}

A \textit{protovoice} is a sequence of edges between notes. The protovoice model is characterised by 3 primitive generative operations on notes.
\par 

\begin{itemize}
  % \setlength\itemsep{1em}
  \item Repetitions: a note of the same pitch is repeated before or after a given note
  \item Neighbor notes: a stepwise ornament to a note. 
  \item Passing notes: notes connecting two protovoices that are separated by a larger interval.
\end{itemize}

These operations relate notes to one or two \textit{parent} notes, which we can describe as rules. Operations on a single parent are represented by attaching a new \textit{child} note with an edge connected to a parent note: 
\begin{equation}
  p \implies x \to p \text{~~~~or~~~~} p \implies p \to x 
  \label{eq:singlesidedinnerop}
\end{equation}
Operations with two parents are represented by edge replacement. 
\begin{equation}
  p_1 \to p_2 ~~~\implies~~ p_1 \to c \to p_2 \label{edge replacement}
  \label{eq:doublesidedinnerop}
\end{equation}
% subsection Inner Structure (end)

\subsubsection{Outer Structure}
\label{sub:Outer Structure}

The inner structure provided by protovoices captures the sequential and functional organisation of notes, but does not capture when notes are simultaneous. To model simulataneity of notes we introduce \textit{slices}, representing segments of a piece where a group of notes are heard, and \textit{transitions} which contain the protovoice edges between notes in the two neighbouring slices. These provide a higher level abstraction that are used to capture more musical structure. As slices and transitions contain notes and edges respectively, we call the slices and transitions \textit{outer structure}, and the notes and edges contained therein \textit{inner structure}.

\par 
Diagram showing a slice + a diagram showing a higher level slices, grouping an arpegiation.
\par 
A slice $m$ is defined as a multiset of pitches. A transition $t = (s_l, e, s_r)$ relates two slices with a configuration of edges $e=(e_{reg}, e_{pass})$, a set of regular edges (repetition or neighbor), and a multiset of passing edges. This unifies the inner protovoice structure with the outer slice structure. 
\par
The outer structure is transformed by applying three operations recursively:
\par

\FloatBarrier

\begin{figure}
  \centering
  \begin{subfigure}[t]{.28\textwidth}
    \centering\includegraphics[keepaspectratio,width=\textwidth]{outer/split}
    \caption{\texttt{split}}
    \label{fig:splitOp}
  \end{subfigure}
  \begin{subfigure}[t]{.46\textwidth}
    \centering\includegraphics[keepaspectratio,width=0.91\textwidth]{outer/spread}
    \caption{\texttt{spread}}
    \label{fig:spreadOP}
  \end{subfigure}
  \begin{subfigure}[t]{.24\textwidth}
    \centering\includegraphics[keepaspectratio,width=\textwidth]{outer/freeze}
    \caption{\texttt{freeze}}
    \label{fig:freezeOp}
  \end{subfigure}

  \captionsetup{width=.9\linewidth}
  \caption{The three operations on outer structure as described in \cite{finkensiepModelingInferringProtovoice2021}. \\
  The original slices and transitions are shown at the top of each diagram, while the lower part shows the generated structure after each outer operation is applied.}
  \label{fig:outerOperations}
\end{figure}

\begin{itemize}
  \item A \textbf{split} replaces a transition $t$ by inserting a new slice $s'$ and two surrounding transitions $t_l$ and $t_r$. Each of the edges in $t$ can have by one or more inner operations applied to it. The edges generated by these inner operations can either be discarded, or keep to form the new edges of $t_l$ and $t_r$.
\begin{equation}
  t \to t'_l~s'~t'_r
  \label{eq:splitrule}
\end{equation}
  \item A \textbf{spread} replaces a slice $s$ by distributing its notes to two child slices $s'_l$ and $s'_r$. 
\begin{equation}
  t_l~s~t_r \to t'_l~s'_l~t'_m~s'_r~t'_r
  \label{eq:spreadrule}
\end{equation}
\item A \textbf{freeze} marks a transition as terminal, such that the edges within the transition can no longer have operations applied to it. 
\begin{equation}
  t \to \underline{t}
  \label{eq:freezerule}
\end{equation}
\end{itemize}

\FloatBarrier

\subsubsection{Proto-voice harmony}



How do we get from a proto-voice (partial)derivation to a harmonic inference?
\par
Explain what harmony is, and how the proto-voice model allows us to capture harmony. Elaboration of the introduction. Explain the problem of chord tone identification, and it's relation to voice leading (repeition and ornamentation) and protovoices.
\par
What assumptions are needed for a protovoice derivation to be able to describe harmonic entities? These shape heuristic design.
\par
Score with latent harmony. 
\par
Explain what is meant by a reduction 
\par 
What is meant by a partial reduction
\par 
The partial reduction which is the goal (one slice per chord label). Our goal when parsing is ascertain slices that correspond to the chord labels, having explicit explained away ornementations through the protovoice edges. 

\subsection{Probabilistic Programming}
Probabilistic programming is the combination of model definitions and statistical inference algorithms for computing the conditional distribution of inputs that could have given rise to the observed output. 
\par 
In the context of ACE, we can reframe the generation of a piece as having the underlying sequence of chord labels as an \textbf{input}, and the musical surface or score being the \textbf{observed output}. 
\par 

We can \textit{factorize} a probabity distribution into a \textit{prior} and a \textit{likelihood}. By choosing priors that are conjugate to the likelihood, we get a posterior distribution that is 

Provide an explanation of all the concepts I learned and used in this project. 
Techniques such as marginalisation, joint distributions, bayes rule etc. 

Dirchelet distributions

Beta distribution  

Multinomiall distribution 

Normal Distribution 

\par 
Inference as model $\to$ data $\to$ prob distribution $\to$ chord guess

\subsection{Probabilistic Model of Harmony}
We are making the assumption that the score is a realisation of the latent harmonic entities. 

Outline of the probabilistic model of harmony, describing the parts that are relevant for harmonic annotations. This section allows the reader to understand the evaluation and heuristic modules.

\subsubsection{Model definition}
We have a set of pitches $\mathcal{P}$ and a set chord-types $\mathcal{C}$. A chord label is defined as a tuple of \textit{root note} pitch and chord-type: $\mathcal{L} = \mathcal{P} \times \mathcal{C}$. We perform a transform of the pitches of each note relative to the chord's root note that is being considered, such that we only need to consider the chord type. 

\par
The priors for the model are as follows:
\begin{equation}
\begin{align*} 
              && \vec{\chi} &\sim \text{Dirichlet}(0.5, |\mathcal{C}|)     && \text{prior of the chord type} \\
              && \lambda &\sim \text{Gamma}(3, 1)     && \text{prior of the note rate} \\
  \forall c:  && \theta_c  &\sim \text{Beta}(1, 1)        && \text{prior of each note being a chordtone/ ornament} \\
  \forall c:  && \vec{\phi}_{ct}^{c}  &\sim \text{Dirichlet}(0.5, |\mathcal{P}|)        && \text{pitch for each ornament} \\
  \forall c:  && \vec{\phi}_{or}^{c}  &\sim \text{Dirichlet}(0.5, |\mathcal{P}|)        && \text{pitch for each chord tone} \\
  % \forall i:  && L_i | \vec{\chi} &\sim \text{Categorical}(\vec{\chi}) && \text{chord label of each data point} \\
  %             && N_i | L_i, v &\sim \text{Multinomial}(v_{L_i})  && \text{notes of each data point} \\
\end{align*}
\label{eq:phm}
\end{equation}
\par 
Given this model we can use it to generate a single chord as follows:

\par
Then describe how to go from the parameters to chord, chordtone and ornamentation distributions
\par

\subsubsection{Model inference}
Given the model, we can use a dataset to learn the parameters of the model. These parameters can then be used for inference as follows.
For each datapoint, the chord label 
\begin{equation}
\begin{align*} 
  \forall i:  && L_i | \vec{\chi} &\sim \text{Categorical}(\vec{\chi}) && \text{chord label of each data point} \\
              && N_i | L_i, v &\sim \text{Multinomial}(v_{L_i})  && \text{notes of each data point} \\
\end{align*}
\label{eq:chordlabeldp}
\end{equation}

\par
Chordtypes, $C = \{\text{M,~m, Mm7, om, o7, mm7, \%7, MM7, +, Ger, It, Fr, mM7, +7}\}$

\[\vec{\chi}' \sim \text{Dirchlet} (\text{pHarmonies}, n_c) \]

\[\vec{\chi} = \mathbb{E} (\vec{X}_i) = \frac{\alpha_i}{\sum\limits_j \alpha_j} \]

Chord: \[c \sim \text{Categorical}(\vec{\chi})\]

Single chordtone distribution. We want to find $P(p|c, ct)$ probability of the pitch given the chord, and that the note is a chordtone:
\[\vec{\phi}_{ct}' \sim \text{Dirchlet}(pChordtones, n_p) \implies \vec{\phi}\]

For each of these parameters we use the MLE to get our probability distribution. 
\[\vec{\phi}_{ct} = \text{MLE} (\vec{\phi}_{ct}')\]
\[\vec{\phi}_{or} = \text{MLE} (\vec{\phi}_{or}')\]
\[\vec{\chi}= \text{MLE} (\vec{\chi}') \]
Then for each chord tone,
\[p_{ct} \sim \text{Categorical}(\vec{\phi}_{ct})\]
\[p_{or} \sim \text{Categorical}(\vec{\phi}_{or})\]
We get the distribution of likelihoods for each pitch.

\subsection{Heuristic Search Algorithms}
Heuristic search algorithms are a subset of search algorithms used to find a sequence of actions from an initial state that results in a goal state. The problem is defined as follows:
\begin{itemize}
  \item We have an \textit{initial state} $s_0$ where $s_0 \in S$, the set of possible states
  \item We have set of \textit{actions} $A$, modelled by the function $action: A\times S \to S$
  \item We have \textit{goal test}, modelled by the function $goal: S \to \{true, false\}$
  \item There is a \textit{cost} associated with every path, modelled by $cost: A \times S \to \mathbb{R}$
  \item Finally, we have a function \textit{expand} is a \textit{cost} associated with every path, modelled by $cost: A \times S \to \mathbb{R}$
  \item We wish to find the minimum cost path from the initial state $s_0$ to a goal state. 
  % \item We have an initial state $s_o \in S$, which is the empty reduction, corresponding to the unreduced surface of the piece. The score is represented as a sequence of slices grouping notes that sound simultaneously. We are also given the segmentation of the original chord labels that we wish to retrieve.
  % \item We have a set of actions, $A$ modelled by a function $action: A \times S \to S$. These actions correspond to a single reduction step.
  %   \begin{itemize}
  %     \item The reduction steps are the inverses of the operations defined by the generative proto-voice model.
  %   \end{itemize}
  % \item Finally we have a goal test, $goal: S \to \{true,false\}$ which is true iff the partial reduction $s$ has exactly one slice per segment of the input.
  %   \begin {itemize}
  % \item This means the partial reduction $s$ contains a sequence of slices which start and end positions corresponding to the segmentation of the piece.
  %   \end {itemize}
  % \item At the first stage, this will be implemented using a random graph search algorithm, picking each action randomly, according to precomputed distributions.
  % \item The state space $S$ is the set of all possible partial reductions of a piece along with each reduction step that has been done so far. 
  % \item We have an initial state $s_o \in S$, which is the empty reduction, corresponding to the unreduced surface of the piece. The score is represented as a sequence of slices grouping notes that sound simultaneously. We are also given the segmentation of the original chord labels that we wish to retrieve.
  % \item We have a set of actions, $A$ modelled by a function $action: A \times S \to S$. These actions correspond to a single reduction step.
  %   \begin{itemize}
  %     \item The reduction steps are the inverses of the operations defined by the generative proto-voice model.
  %   \end{itemize}
  % \item Finally we have a goal test, $goal: S \to \{true,false\}$ which is true iff the partial reduction $s$ has exactly one slice per segment of the input.
  %   \begin {itemize}
  % \item This means the partial reduction $s$ contains a sequence of slices which start and end positions corresponding to the segmentation of the piece.
  %   \end {itemize}
  % \item At the first stage, this will be implemented using a random graph search algorithm, picking each action randomly, according to precomputed distributions.
\end{itemize}

The way we solve these problems is through a graph search, with each node representing a state, and each edge representing an action and associated cost. At each iteration, we incorporate a \textit{policy}(search strategy) which determines which nodes in the search tree are chosen to be expanded. Typically, in these problems the search state is intractable, such that a breadth first search would not be feasible. As such, a priority queue is used to choose which nodes to expand, with the priority being calculated using a \textit{heuristic}.

\subsubsection{Best First Search}
\subsubsection{Greedy search}
\subsubsection{Exhaustive search}
\subsubsection{Beam search}
As a result of the very large branching factor in the graph of partial reductions, even a best-first search would lead to memory overflow. Beam search is an optimisation of best-first search that serves to reduce its memory requirements. 




%
% Provide an outline of the heuristic search paradigm with a formalisation.
% \par
% Provide a brief overview of different techniques that are used to prune the search space that might be relevant.

\section{Starting Point}

\subsection{Relevant courses and experience}

\paragraph{Haskell}{I was introduced to Haskell during an internship during the summer before starting this project (July to August 2022). As a result, I had 2 months of experience with the language beforehand. I chose to use Haskell in order to further familiarise myself with the language, and because of its amenability to parsing algorithms.}

\paragraph{Python}{I have experience coding in Python from personal projects as well as the 1A \textit{Scientific Computing Practical Course}. This was chosen to made use of powerful existing libraries for handling large datasets and running experiments. }

\paragraph{IB}{ Two modules from 1B provide a foundation for this project. \textit{Formal Models of Language} introduces the ideas and terminology used in the protovoice model, and \textit{Artificial Intelligence} provides a background for classical search algorithms as well as some of the probabilistic frameworks used in the project.}

\subsection{Existing codebase}
\subsubsection{Protovoices-haskell}
This project was implementated in a fork of the pre-existing \textit{protovoices-haskell} github repository. This repository contains custom data structures and types, allowing interoperability with other projects making use of the same model. I also make use of learned parameters from the implementation of the paper \textit{Bayesian Model of Extended Chord Profiles}\cite{finkensiepChordTypesOrnamentation2023}. 

The following describes the protovoices-haskell repository, and where my code contribution will lie:
\par
\medskip
\dirtree{%
.1 protovoices-haskell.
.2 app.
.3 MainExamples.hs.
.3 MainISMIR.hs.
% .3 MainLearning.hs.
% .3 MainHeuristicSearch.hs <- My code.
.3 ....
.2 src.
.3 \textbf{Heuristics} <- My code.  
% .4 …  <- My code.
.3 ....
.2 test.
% .2 testdata.
.2 ....
}

\section{Requirements Analysis}



\begin{table}[ht]
  \caption{Project Deliverables}
  \vspace{\baselineskip}
  \label{requirements}
  \centering
  \begin{tabularx}{0.9\textwidth}{cXcc}
    {\large \textbf{ID}} & \large \textbf{Deliverable} & \large \textbf{Priority} & \large \textbf{Risk} \\
    \toprule
    \texttt{core1} & Evaluation Module & High & Low \\
  \texttt{core2} & End to End Pipeline  & High & Medium \\
    \texttt{core3} & Parser & High & High \\
    \texttt{base1} & Random Choice Parser & High & Low \\
    \texttt{base2} & Random Sample Parser & Medium & Low \\
    \texttt{ext1} & Heuristic Search 1 & Medium & High \\
    \texttt{ext2} & Heuristic Search 2 & Low & High \\
  \end{tabularx}
\end{table}

\par
Short description of where the risk lies. 
\par
Pertt chart showing the dependencies between different modules


\section{Software Engineering Techniques}
Justified and documented selection of suitable tools; good engineering approach.


\subsection{Development model}

Usig the dependency and risk analysis above, I created this gantt chart, and totally stuck to it(100\% didn't wait until now to get the end-to-end pipeline fully running, and spend most of the time in an extension rabbit hole.. We live and we learn).

Include Gantt chart.

Agile? 

Continous integration and frequent commits.

\subsection{Languages, libraries and tools}
The chapter will also cite any new programming languages and systems which had to be learnt 

\begin{table}
  {
  \small
  \caption{Languages, libraries and tools}
  \label{Languages}
  \begin{center}
    \begin{tabularx}{.9\textwidth}{cXc}
      {\large \textbf{Tool}} & {\large \textbf{Purpose}} & {\large \textbf{License}} \\
      \toprule
      Haskell & Main language, used for the core and extension implementations & GHCL \\
      \midrule
      GHC & Compiling and profiling to inspect time performance and memory usage  & BSD-3.0 \\
      \midrule
      Haskell-Musicology & Library with data-types for pitches & BSD-3.0 \\
      \midrule
      Python & Secondary language for experiments and analysis & PSFL \\
      \midrule
      Dimcat & DIgital Musicology Corpus Analysis Toolkit & GPL-3.0 \\
      \midrule
      Numpy & Python library for scientific computing & BSD-3.0 \\
      \midrule
      Pandas & Python library for data manipulation & BSD-3.0 \\
      \midrule
      MS3 & Python library for parsing MuseScore files & GPL-3.0 \\
      \midrule
      Musescore 3 & Music notation software & GPL-3.0 \\
      \midrule
      Protovoice Annotation Tool & Used to view derivations & GPL-3.0 \\
      \midrule
      Docker & Containerised software service used to run experiments on a HPC & Free/Paid \\
      \midrule
      Git & Version Control, Continuous Integration & GPL-3.0 \\
      \bottomrule
    \end{tabularx}
  \end{center}
  }
\end{table}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Implementation
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{Implementation}

\section{Repository Overview:}

\subsubsection{Repository Justification}

The repository has been split into four main folders, with the addition of \texttt{Main.hs} which serves as an interface between the python experiment code and the algorithms developed in Haskell. 
\begin{itemize}
  \item Firstly, the \texttt{src/Core/} folder contains all the core code, including the implementation of the parsing search state and inference functions using the probabilistic model of harmony, as well as some helper code for file handling. 
  \item The \texttt{experiments/} folder contains all the python code that is used for this project. The experiments consist of three stages, as described by the three main files: \texttt{preprocess.py}, \texttt{experiments.py} and \texttt{analysis.py}. Splitting these stages up prevents wasteful computation, as all the pre-processing can be done just once, while experiments are run on the processed data iteratively alongside algorithm development. 
  \item The \texttt{src/Algorithms/} folder contains all the parsing algorithms including the baseline and extension search algorithms. Having all the algorithms contained in one module allows experiments to be run using any selection of algorithms and input data, facilitating the evaluation process.  
  \item Finally, the \texttt{test/} folder contains unit tests and end-to-end tests for use in Continuous Integration.
\end{itemize}

Figure~\ref{fig:blockDiagram} illustrates how these modules are connected. 

% \vspace{50\baselineskip}
\begin{figure}
  \centering
  \includegraphics[width=\textwidth]{blockDiagram.png}
  \caption{Block diagram of project components}
  \label{fig:blockDiagram}
\end{figure}

\FloatBarrier

\DTsetlength{0em}{1.3em}{0em}{0.7pt}{3pt}       
\setlength{\DTbaselineskip}{15pt}  %minimum size for \normalsize
\renewcommand{\DTstyle}{\ttfamily}

\begin{table}[!t]
  % \centering
  \caption{Repository Overview}
  \vspace{\baselineskip}
  \label{jeff}
  \begin{tabularx}{\textwidth}{l X c}
    File/Folder & Description & LOC \\
    \toprule
    \toprule
  \begin{minipage}[t]{5.3cm}
    \dirtree{%
    .1 protovoices-haskell/.
    .2 src/.
    .3 HeuristicParser.hs,~HeuristicSearch.hs \vspace{\DTbaselineskip}.
    .3 RandomChoiceSearch.hs,~RandomSampleParser.hs\vspace{2\DTbaselineskip}.
    .3 Heuristics.hs,~PBHModel.hs \vspace{2\DTbaselineskip}.
    .3 FileHandling.hs\vspace{2\DTbaselineskip}.
    .3 \dots \vspace{\DTbaselineskip}.
    .2 app/.
    .3 MainFullParse.hs\vspace{\DTbaselineskip}. 
    .2 harmonic-inference \vspace{\DTbaselineskip}.
    .2 experiments/.
    .3 preprocess.ipynb.
    .3 experiments.ipynb.
    .3 analysis.ipynb.
    .3 dcml\_params.json.
    .3 inputs/ \vspace{\DTbaselineskip}.
    .2 test/ \vspace{\DTbaselineskip}.
    }
  \end{minipage} &
  \begin{minipage}[t]{8cm}
Root directory
\vspace{2\baselineskip}\\
Core Implementation (Section x)
\vspace{2\baselineskip}\\
Baseline Implemetation (Section x)
\vspace{2\DTbaselineskip}\\
Extension Implementation (Section x) 
\vspace{2\DTbaselineskip}\\
Utilities
\vspace{5\DTbaselineskip}\\
Entry Point
\vspace{3\DTbaselineskip}\\
Running Experiments
\vspace{6\DTbaselineskip}\\
Unit Tests (Section x)

  \end{minipage} & 
  \begin{minipage}[t]{0.5cm}
    2272
    \vspace{0.1\DTbaselineskip}\\
    470\\
    \vspace{\DTbaselineskip}
    121\\
    \vspace{\DTbaselineskip}
    383\\
    \vspace{1.8\DTbaselineskip}
    188\\
    \vspace{3.7\DTbaselineskip}
    431\\
    \vspace{3\DTbaselineskip}
    115\\
    \vspace{2.5\DTbaselineskip}
    611\\
  \end{minipage}
\end{tabularx}
\end{table}

% The repository for this project is a fork of an existing repository that contains useful data-types and functions for working with the protovoice model \cite{finkensiepModelingInferringProtovoice2021}. Uses these allows for interoperability with other projects involving the model.


\section{Core Implementation}

\subsection{Heuristic Parser}
This is not a descriptive name. Think of a new name to describe the implementation of the search space of partial reductions. We use the outer representation of structure and outer operations. This is an abstraction.

\subsubsection{Parsing Operations}
Piece represented by an alternating list of slices and transitions, this is called a path. Define path formally. inductive definitions. dont need the Nothing: just Path trans slice. Transition can be frozen or unfrozen, and boundary or non boundary. Boundary is represented by vertical line, frozen is represented by two lines.

\begin{figure}[ht]
  \centering
  \includegraphics[width=\textwidth]{pathFromSlices}
  \caption{Path initiliasation}
  \label{fig:pathInit}
\end{figure}

\begin{definition}[Path]
A path is an alternating sequence of an two types of elements, in our case transitions and slices. Definition: Haskell code block or mathematical definition?
\end{definition}

Our goal is to reduce the piece into a partial redution by appluying operations until we have one slice per segment. Diagram of this state. This means we have one group of notes per segment, and this group of notes should represent the harmony of the segment.

We parse by applying the inverse of the generative operations, right to left. Unsplit, Unspread, Unfreeze.
\par


\begin{figure}[ht]
  \centering
  \includegraphics[width=\textwidth]{parseops}
  \caption{Parse operations}
  \label{fig:parseops}
\end{figure}

\FloatBarrier
\subsubsection{State Space}

This is how we define the search. We start at the right, the end of the piece. We have a pointer to the current node, and all preceeding slices are open and subsequent slices are frozen. Open Slices can be reduced, but only to the point that there is one slice in a segment. We keep track of the operations performed as it (1). allows us to the draw out the derivation for the partial reduction at the end, and (2). it is used later for calculate a cost for each operation for the heuristic search.




% \begin{figure}[h]
%   \centering
%   \includegraphics[width=\textwidth]{parsestates}
%   \caption{Parse operations}
%   \label{fig:parseops}
% \end{figure}

\begin{figure}[ht]
  \centering
  \includegraphics[width=\textwidth]{searchstate}
  \caption{Search state}
  \label{fig:searchstate}
\end{figure}
\par
\par

\FloatBarrier
\subsubsection{Enumerating State transitions}

\begin{figure}[ht]
  \centering
  \includegraphics[width=0.7\textwidth]{frozenenum}
  \caption{Unfreeze operation}
  \label{fig:frozenenum}
\end{figure}


\begin{figure}[ht]
  \centering
  \includegraphics[width=0.7\textwidth]{sssemiopenenum}
  \caption{Enumeration of operations mid parse. Maybe for appendix? This could be much more concise.}
  \label{fig:sssemiopenenum}
\end{figure}

\begin{figure}[ht]
  \centering
  \includegraphics[width=\textwidth]{statetransitions}
  \caption{State Transition diagram}
  \label{fig:statetrans}
\end{figure}
\FloatBarrier

In the state transition diagram (Figure \ref{fig:statetrans}), we see all the possible parse states (Is this actually useful? Maybe for appendix). This was useful for me as it helps to conceptualise how the full parse actually works. The dimensions of this digramm of the search state depends on the length of the piece, and the size of each segment. We can see that there is a process of moving to the right to unfreeze transitions, and moving towards the left during reduction operations. Perhaps some simplification of the diagram would be useful. This transition diagram does not consider segment boundaries.

sdfsdfs

sdf

\FloatBarrier
\subsubsection{Boundary handling}

It is important thhat we don't reduce to an empty segment, because that would mean we've lost all information about the segment, and would not be able to make a harmonic inference. In order to prohibit this, we add additional constraints to the parse operations for each opertation based on the boolean boundary value of all involved transitions.
\par
We use karnaugh maps to determine the boolean expression for these constraints.

\begin{figure}[ht]
  \centering
  \includegraphics[width=0.7\textwidth]{karnaughunfreeze}
  \caption{Determine boolean boundary expressions for the freeze operations}
  \label{fig:karnaugh}
\end{figure}

\par 
Could show other maps in the appendix.


\FloatBarrier
\subsection{Evaluation Module}
We need to know exactly what we are trying to achieve before we can understand the baseline and extention implementations.

\FloatBarrier
\subsubsection{Probabilistic Model of Harmony}
When evaluating using the protovoice model: we assume that we result in only chord tones for each segment. Thus we can use the chord tone probabilities to evaluate the prediction. 
\par
When just using a random sample, we have to assume that there is a mixture model of chord tones and ornaments. We can use the learnt parameters to determine the distribution.
\par
These two measures of likelihoods are comparable as they are drawn from the same distributions.
\par
We also need to infer chord labels. We can simply choose the chord that is most likely according to our model.
\par 
This gives us two key metrics, likelihood and accuracy.
\par
Could also use a more sophisticated notion of accuracy, using a chord similarity function \cite{humphreyFourTimelyInsights2015}. The {\texttt {mir\_eval}} package provides a plethora of metrics to compare chord label predictions \cite{raffelMirEvalTransparent2014}. 

\section{Baseline implementation}


\subsection{Random Sample Parser}
As a crude baseline we develop two algorithms based on randomly sampling notes for each segment to infer the chord label. 
\par
The pure random sample algorithm simply samples random notes for each segment, and uses those to guess the chord label. This doesn't even consider the notes of the piece, so it's really bad, but provides a useful reference.
\par 
The per segment sample algorithm samples notes from each segment. Could just sample a random number of notes from each segment, or just use all the notes in the segment to predict the most likely chord label. This is reminiscent of using a key-profile model \cite{temperleyBayesianApproachKeyFinding2002} to find local keys.

\FloatBarrier
\subsection{Random Choice Search}
Now we use our implementation of the protovoice parser, but just do a random walk in the tree of partial reductions. By comparing this against the random ample parser, we can get an idea of the utility of the model. We show that this works surprisingly well.

\FloatBarrier
\section{Extension Implementation}

\subsection{Heuristic Design}
Step 1: Design heuristic to be as accurate as possible. I.e the extreme is to consider every possible parse, but for a single piece there can be over $10^{10^{10^{10^{10^{10}}}}}$ different parses. We consider 1 step at a time at first - this still results in needing to choose an operation out of upwards of 30,000,000 options for just a single step.     
\par
First the full piece heuristic parse 
\par
Problem of very large slices.\\ 
Segment by segment heuristic parse - avoids the problem, but is slightly hacky. Can we incorprate our knowledge regarding the relative proportion of chord tones and ornaments. Should we allow duplicates of notes in slices? Perhaps we should favour spreads more. 
\par
Always consider a certain number of slices and spreads.
\par

\begin{figure}[ht]
  \centering
  \includegraphics[width=0.7\textwidth]{splitsssemiopen}
  \caption{Split operation}
  \label{fig:splitoperation}
\end{figure}

\FloatBarrier
\subsubsection{Scoring Unsplit Operations}
Consider the Split rule : \[t \to t'_{l}~s'~t'_{r}\]
\par
During a split, each edge in the transition and each node in an adjacent slice can be elaborated by one or more inner operations.
These new edges can be discarded or kept to form the new edge of $t'_l$ and $t'_r$.
\par 
The notes in the child slice $s$ can either have edges connected to the left neighboring slice or right neighbouring slice, or both. I.e for each note in the child slice, it can be a an ornmentation of a previous note, subsequent note, both, or repetition of prev note, subsequent note etc. So we consider the chord tone profiles of the involved slices. 

We first guess the chord type each parent slice. 
\[\theta_l = \mathop{argmax}_{c \in C} P(s_l|c) ~~,~~ \theta_r = \mathop{argmax}_{c \in C} P(s_r|c) '\]

We now consider each edge individually, considering their likelihoods based on the proabilistic model of harmony along with theoretical assumptions. 

\paragraph{Single Sided Operations} 
\begin{itemize}
  \item Right Neighbour (Left Neighbour anagolously)
    \[ x \implies x \to n~~, x,n \in P \]
    \[x \sim \text{Categorical}(\sigma_{ct}^{\theta_l})\]
    \[n \sim \text{Categorical}(\sigma_{or}^{\theta_r})\]
    Find \[P(x,n~|~\theta_l)\]
  \item Right Repeat (Left Repeat anagolously)
    \[ x \implies x \to x~~, x \in P \]
    \[x \sim \text{Categorical}(\sigma_{ct}^{\theta_l})\]
    Find \[P(x~|~\theta_l)\]
\end{itemize}
\paragraph{Two Sided Operations} 
\begin{itemize}
  \item Root Note: This operation is only done once in the original model. In our case we do not need to consider due to segment boundaries.
  \item Full Repeat: 
    \[ x \implies x \to n~~, x,n \in P \]
    \[x \sim \text{Categorical}(\sigma_{ct}^{\theta_l})\]
    \[n \sim \text{Categorical}(\sigma_{or}^{\theta_r})\]
    Find \[P(x,n~|~\theta_l)\]
  \item Left Repeat of Right: 
    \[ x \to y \implies x \to y' \to y \]
    \[y \sim \text{Categorical}(\sigma_{ct}^{\theta_l})\]
    Find \[P(y~|~\theta_l)\]
  \item Full Neighbour:
    \[ x_1 \to x_2 \implies x_1 \to n \to x_2, x \in P \]
    % \[x \sim \text{Categorical}(\sigma_{ct}^{\theta_l})\]
    Find \[P(|~\theta_l,\theta_r)\]
\end{itemize}

\FloatBarrier
\subsubsection{Scoring Unspread Operations}

Consider the Spread rule : \[t_l s_r \to t'_l s_l t'_m s_r t'_r\]
We make the assumption that $s$, $s_l$, \& $s_r$ are all realisations of the same chord. This lines up with the music theorretical basis for this operation in the model(justify).
\par 
Thus we find the most likely chord (optional extension: marginalise over all chords)
\[\theta = \mathop{argmax}_{c \in C} P (s|c)\]
\par 
When then measure the extent to which the parent slics match this chord.

\[p(s_l, s_r| \theta)\]

We can calculate $p(s_l|\theta)$ and $p(s_r|\theta)$ using the multinomial distribution probability density function as described in the preparation chapter.

\FloatBarrier
\subsubsection{Scoring Unfreeze Operations}
We assign 0 cost to unfreeze operations. This means we need to be careful about ensure that we don't just unfreeze the entire piece immediately. Careful construction of the search algorithm can ensure this. More later.

\FloatBarrier
\subsubsection{Full state evalutation}
We need to combine all of these in a fair way. Also the distinction between splits and spreads need to be considred, as they are different operations, the calculations of likelihood may cause an imbalance. All likelihoods are stored in log space.

\FloatBarrier
\subsection{Heuristic Search}
Step 2: Relax the heuristic search in order to reduce runtime/ lower complexity.
\par 
In the case that there are 85,000,000 options, perhaps we should sample the options rather than evaluating all of them. 
\par 
This version of heuristic search should be able to parse full pieces (hopefully), so can be used to compare with the baselines on an entire corpus.
\par 
Beam of size n, with 1 for a freeze, k for spread, n-k-1 



\section{Testing}
Show unit tests, and examples of the test/development cycle for the heuristic search development

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Evaluation
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{Evaluation}
\textit{In this chapter, I provide qualitative and quantitative evaluations of the work completed. I then provide and interpret evidence to show that the success criteria were met.}

\textit{The main questions to answer are as follows:}
\begin{itemize}
  \item \textit{Can the proto-voice model be used to accurately infer chord labels?}
  \item \textit{Can the proto-voice model be used to practically infer chord labels?}
  \item \textit{How well my heuristic search algorithms infer chord labels?}
\end{itemize}

\section{Accuracy}
Things to note
\begin{itemize}
  \item The fact that segmentation is known ahead of time provides a great deal of information \cite{gothamWhatIfWhen2021}
  \item So we can use comparisons between the random sample from each segment algorithm and the random parse algorithm to see if the use of the grammar provides an advantage over just sampling the notes directly, without looking at relations between notes.
  \item Then we want a heuristic search algorithm that considers each option exhaustively and finds the best local option. This is too computationally expensive to be used for whole pieces. 
  \item Given there can be millions of possible next states in the search, we need to look at different strategies to avoid searching through them all. E.g just sample states. 
  \item Sensitivity Analysis for the heuristic search is useful for the evaluation. Explore how robust it is to handcrafted attacks/ different types of passages.
  \item Could evaluate by segments instead of pieces. 
\end{itemize}

\section{Performance}

\section{Heuristic Search (Extension)}

\section{Success Criteria}

\section{Limitations}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Conclusions
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{Conclusions}
\textit{In this chapter, I first discuss the success achieved by the project then offer a reflection on lessons learned. Finally, I consider the directions in which there is potential for future work.}
\section{Achievements}

\section{Lessons learned}

\section{Future Work}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% the bibliography
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\addcontentsline{toc}{chapter}{Bibliography}

\nocite{*}
% \addbibresource{Disseration.bib}
\bibliography{Dissertation}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% the appendices
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\appendix

\chapter{Additional Information}

% \section{metadata.tex}
% {\scriptsize\verbatiminput{metadata.tex}}
%
% \section{main.tex}
% {\scriptsize\verbatiminput{main.tex}}
%
% \section{proposal.tex}
% {\scriptsize\verbatiminput{proposal.tex}}
%
% \chapter{Makefile}
%
% \section{makefile}\label{makefile}
% {\scriptsize\verbatiminput{makefile.txt}}
%
% \section{refs.bib}
% {\scriptsize\verbatiminput{refs.bib}}


\chapter{Project Proposal}

\input{proposal}

\end{document}
